---
title: 面试准备
date: 2024-04-23 19:55:39
tags:相关问题
---

# 黑马点评相关问题

## 1. 项目里为什么要用消息队列：

在异步秒杀优惠券的业务中，涉及访问数据库的操作包括：根据优惠券id查询优惠券信息、查询当前用户是否已经购买过该优惠券、库存扣减、新增订单。串行执行的时候会相当消耗时间，于是对业务进行异步化改造。

使用阻塞队列的话，它用的是jvm内存，在高并发场景下可能会导致内存的溢出；同时，由于内容都是存在内存中，如果发生宕机，内存中的数据丢失会导致安全问题。因此选择使用消息队列来进行处理。

## 2. 请求很多，消息堆积处理不过来了如何应对（消息积压）

* 消费者扩容：如果当前主题（Topic）的消息队列数量大于消费者数量，可以通过增加消费者来扩容，从而提高消费能力，尽快消费积压的消息。通过增加消费者，可以使消息队列分配给更多的消费者进行并行消费，加快消息处理速度
* 消息迁移Queue扩容： 如果当前主题的消息队列数量小于或等于消费者数量，增加消费者可能无法有效提高消费能力。这时需要考虑**扩容消息队列。** 
  * **一种方法是创建一个临时主题**，在临时主题上设置更多的消息队列。然后将部分消费者用于将消息从原主题转发到临时主题，这个过程不需要进行业务处理，只是简单地将消息转发，因此速度很快。接下来，使用扩容后的消费者来消费临时主题中的消息。当所有积压消息都被消费完毕后，可以恢复到原始状态。

## 3. 用户在消息堆积时以为卡了，多次请求怎么处理

前端在用户点击按钮之后，禁用按钮直到有结果返回。

## 4. 项目都有哪些表

博文表、博文的评论表、关注表、秒杀优惠券表、优惠券表、店铺信息表、店铺类型表（美食、酒吧等，以及关联icon）、用户信息表、优惠券订单表。

##  5. 超卖问题怎么解决？

使用乐观锁解决超卖问题，这里直接对比库存值，在进行扣减操作之前会查询库存stack值，在进行扣减操作时，检查stack（内存中的值V）是否与最开始读到的值（预期原始值A），如果相同则可以进行扣减，反之，不同的话说明有其他线程更改过库存了，此时应该进行重试工作。

## 5. 秒杀场景下扣减库存太慢了怎么解决

* 采用上面所说的异步执行秒杀逻辑的方法
* 对库存进行拆分，比如将十万库存，分成100段，每段1000个库存。对应的，有100把锁去锁这100个库存段了，可以满足100个线程同时跑。

## 7. Redis大key怎么解决？

大key是指简单的key存储的value过大，或者hash，set，zset，list中存储过多的元素。

大key会导致如下问题：

* 客户端耗时增加：数据量大导致网络传输时间会增加，导致响应时间增加
* 带宽和cpu资源占用过高：对大key进行读写操作时，会严重影响redis的性能和吞吐量。
* 数据倾斜：大key集中到某个redis节点上时，会导致数据在redis中集群中的分布不均衡，造成节点负载不均
* 阻塞问题：对大key进行删除或清理工作时，可能会导致redis阻塞。删除时会占用大量的CPU和IO资源导致响应变慢。在被动删除大key时，当redis内存不足时，会触发内存淘汰机制，可能导致部分大key被删除。

**删除大key:**

* 当Redis版本大于4.0时，可使用UNLINK命令安全地删除大Key，该命令能够 以非阻塞的方式，逐步地清理传入的Key。
* 当Redis版本小于4.0时，避免使用阻塞式命令KEYS，而是建议通过SCAN命 令执行增量迭代扫描key，然后判断进行删除。

**压缩和拆分key:**

* 当vaule是string时，比较难拆分，则使用序列化、压缩算法将key的大小控制 在合理范围内，但是序列化和反序列化都会带来更多时间上的消耗。
* 当value是string，压缩之后仍然是大key，则需要进行拆分，一个大key分为不 同的部分，记录每个部分的key，使用multiget等操作实现事务读取。
* 当value是list/set等集合类型时，根据预估的数据规模来进行分片，不同的元 素计算后分到不同的片。

总结：

1. 对bigkey进行拆分，比如一个hash结构的key，可以拆成多个hash来存储
2. 直接删除bigkey，redis4.0起提供了unlink的非阻塞删除key方式
3. 对value采用压缩算法，如果压缩后还是很大，那么就继续拆分
4. 对失效的数据进行定期的清理

## 8. 什么是热Key

热key就是一个非常热销的产品，比如突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。

## 9. 如何解决热key问题

方案主要有两种：

1. 利用二级缓存：比如ehcache或者hashmap，都可以作为二级缓存，当发现热key之后，把热key加载到jvm中，而针对这种热key请求，会直接从jvm中获取，而不是从redis中，比如一个十万的请求，应用层有50台机器，那么每台机器备份到2000个请求，还是可以处理的
2. 备份热key：就是在redis集群当中，将这个key在多个redis上都进行保存，那么当有请求过来时，从集群当中挑选一个区访问进行取值

## 10.  短信登录的短信怎么发送的



## 11. 项目的拦截器详细讲讲

## 12. 怎么保存验证码

## 13.项目里存在redis里的key的格式，存的什么

## 14. 如何标识用户

手机号作为用户标识

## 15.项目的权限刷新什么意思

## 16. 旁路缓存机制具体解决的什么场景

## 17 更新缓存失败了怎么办

涉及Redis的高可用.

当客户端发现master节点不可写后，可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间后（master恢复正常后）重新写入master来保证数据不丢失。也可以将数据写入Kafka消息队列，等master恢复正常，再隔一段时间去消费Kafka中的数据，将数据重新写入master。

## 重试的时候，缓存中的错数据被访问多次了，怎么解决

## 项目为什么要加个消息队列

## 抢优惠券没有及时处理怎么办

## 抢优惠券处理完了如何通知用户

## Redis的Zset

Zset是redis当中的SortedSet，比set多了一个score值，按score值升序排序

那么zset底层依靠的是ziplist或者skiplist实现，当如果有序集合的元素个数小于 `128` 个，并且每个元素的值小于 `64` 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；

但是其实使用skiplist，是将skiplist和dict一起进行包装，使用通dict中的entry记录key和value，使用skiplist记录score，从而通过dict进行键值的存储，通过，skiplist存储socre并进行排序和快速的查找

当使用ziplist时，逻辑是将score和element连续存储

## Zset的范围查询的时间复杂度是多少

`ZRANGE` 或 `ZRANGEBYSCORE`，其时间复杂度是 O(log N + M)，其中 N 是有序集合中的元素数量，M 是返回的元素数量。

这是因为 Redis 内部使用了跳跃表（skip list）实现有序集合，而跳跃表的查询时间复杂度是 O(log N)。在执行范围查询时，Redis首先定位到开始的元素，然后按顺序移动到结束的元素，因此时间复杂度还取决于返回的元素数量 M。